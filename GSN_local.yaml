!obj:pylearn2.train.Train {
  dataset: &X !obj:pylearn2.datasets.moons.Moons {
    num_X: 500,
    noise: 0.01
  },
  model: !obj:pylearn2.models.autoencoder.DivergenceGSN_local {
    act_dec: !obj:pylearn2.models.mlp.MLP {
      layers: [
        !obj:pylearn2.models.mlp.Tanh {
          layer_name: 'enc_tanh_1',
          dim: 16,
          irange: 0.2,
        },
        !obj:pylearn2.models.mlp.Linear {
          layer_name: 'enc_linear_3',
          dim: 2,
          irange: 0.2,
        }
      ],
      nvis: 2,
    },
    corruptor: !obj:pylearn2.corruption.TrainableGaussianCorruptor {
      stdev: 0.3,
    },
    decorruptor: !obj:pylearn2.corruption.TrainableGaussianCorruptor {
      stdev: 0.05,
    }
  },
  algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
    learning_rate: 0.005,
    batch_size: 2,
    monitoring_dataset: {
      train: *X,
    }, cost: !obj:pylearn2.costs.autoencoder.DivergenceCost_local {
      X: *X,
      num_samples: 500,
      num_encodings: 1,
    }
  },
  extensions: [
    !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
      channel_name: 'train_cost',
      save_path: '${PYLEARN2_TRAIN_FILE_FULL_STEM}_best_cost.pkl'
    # }, !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
    #   channel_name: 'train_dec_stdev',
    #   save_path: '${PYLEARN2_TRAIN_FILE_FULL_STEM}_best_dec_stdev.pkl'
    },
    !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
      start: 10,
      saturate: 200,
      decay_factor: 0.1,
    }
  ],
  save_path: '${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl',
  save_freq: 50,
}
