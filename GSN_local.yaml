!obj:pylearn2.train.Train {
  dataset: &X !obj:pylearn2.datasets.moons.Moons {
    num_X: &num_X 100,
    noise: 0.01
  },
  model: !obj:pylearn2.models.autoencoder.DivergenceGSN_local {
    act_dec: !obj:pylearn2.models.mlp.MLP {
      layers: [
        !obj:pylearn2.models.mlp.Sigmoid {
          layer_name: 'dec_tanh_1',
          dim: 10,
          irange: 2.8,
        },
        !obj:pylearn2.models.mlp.Linear {
          layer_name: 'dec_linear_2',
          dim: 2,
          irange: 0.7,
        }
      ],
      nvis: 2,
    },
    corruptor: !obj:pylearn2.corruption.TrainableGaussianCorruptor {
      stdev: 0.5,
    },
    decorruptor: !obj:pylearn2.corruption.TrainableGaussianCorruptor {
      stdev: 0.05,
    }
  },
  algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
    learning_rate: 0.001,
    batch_size: 10,
    monitoring_dataset: {
      train: !obj:pylearn2.datasets.moons.Moons {
          num_X: 100,
          noise: 0.01
      },
    },
    cost: !obj:pylearn2.costs.autoencoder.DivergenceCost_local {
      X: *X,
      num_encodings: 10,
    }
  },
  extensions: [
    # !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
    #   channel_name: 'train_cost',
    #   save_path: '${PYLEARN2_TRAIN_FILE_FULL_STEM}_best_cost.pkl'
    # # }, !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
    # #   channel_name: 'train_dec_stdev',
    # #   save_path: '${PYLEARN2_TRAIN_FILE_FULL_STEM}_best_dec_stdev.pkl'
    # },
    !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
      start: 10,
      saturate: 200,
      decay_factor: 1.,
    }
  ],
  save_path: '${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl',
  save_freq: 50,
}
