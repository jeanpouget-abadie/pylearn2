!obj:pylearn2.train.Train {
    dataset: !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        start: 0,
        stop: 50000
    },
    model: !obj:pylearn2.models.mlp.MLP {
        nvis: &x_dim 784,
        layers: [
            !obj:pylearn2.models.mlp.Tanh {
                layer_name: "encoding_layer_q",
                dim: &h_dim 500,
                irange: 0.01
            },
            !obj:pylearn2.models.mlp.CompositeLayer {
                layer_name: "composite_layer_q",
                layers: [
                    !obj:pylearn2.models.mlp.Linear {
                        layer_name: "mean_layer_q",
                        dim: &z_dim 200,
                        irange: .01
                    },
                    !obj:pylearn2.models.mlp.Linear {
                        layer_name: "sig_layer_q",
                        dim: *z_dim,
                        irange: .01
                    }
                ]
            },
            !obj:pylearn2.models.mlp.SamplingLayer {
                layer_name: "sampling_layer"
            },
            !obj:pylearn2.models.mlp.Tanh {
                layer_name: "encoding_layer_p",
                dim: *h_dim,
                irange: 0.01
            },
            !obj:pylearn2.models.mlp.CompositeLayer {
                layer_name: "composite_layer_p",
                layers: [
                    !obj:pylearn2.models.mlp.Sigmoid {
                        layer_name: "bernoulli_layer_p",
                        dim: *x_dim,
                        irange: .01
                    }
                ]
            }
        ]
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        batch_size: 100,
        learning_rate: .001,
        monitoring_dataset: {
            test: !obj:pylearn2.datasets.mnist.MNIST {
                which_set: "test",
            },
        },
        cost: !obj:pylearn2.costs.variational.BernoulliVariationalCost {
        }
    }
}

